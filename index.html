<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting">
  <meta name="keywords" content="Splannequin">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Turning Hand-Held Freeze-Pose Footage into Static 3D with Dual-Detection Splatting</title>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <!-- <link rel="stylesheet" href="./static/css/bootstrap.min.css"> -->
  <!-- <link rel="stylesheet" href="./static/css/app.css"> -->
  <link rel="icon" href="./static/images/favicon.webp">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>
  <script src="./static/js/app.js"></script>
</head>
<body>

<section class="hero" style="background: linear-gradient(135deg, #e6f4f7, #d1ecf5, #b8e0eb); padding: 10px 10px;">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title neon-text" style="font-size: 6rem; margin-bottom: 30px;">
            Splannequin
          </h1>
          <h2 class="subtitle is-2 publication-subtitle subtle-glow" style="font-size: 2.1rem;">
            Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting
          </h2>
          <h3 class="subtitle is-1 publication-subtitle"><strong>WACV 2026</strong></h3>
          <div class="is-size-3 publication-authors">
            <span class="author-block">
              <a href="">Hao-Jen Chien</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yichuanh.github.io/Personal-Page/">Yi-Chuan Huang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://kkennethwu.github.io/">Chung-Ho Wu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://sites.google.com/view/wei-lun-harry-chao">Wei-Lun Chao</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://yulunalexliu.github.io/">Yu-Lun Liu </a><sup>1</sup>,</span>
          </div>

          <div class="is-size-3 publication-authors">
            <span class="author-block"><sup>1</sup>National Yang Ming Chiao Tung University,</span>
            <span class="author-block"><sup>2</sup>Ohio State University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">

              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>paper (coming soon)</span>
                </a>
              </span>


              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>

              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <img src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" width="20" height="20" alt="HF">
                  </span>
                  <span>Dataset (Coming soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser" style="margin-top: 60px;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="pipeline-figure">
        <img src="./static/images/teaser.jpg" alt="Teaser" style="width: 100%; margin-bottom: 30px;"/>
      </div>
      <p class="subtitle is-2 has-text-centered">
        <strong>Splannequin</strong> transoforms imperfect Mannequin-Challenge videos to be completely frozen.
      </p>
      <p class="has-text-justified">
        (Top) A monocular Mannequin-Challenge video is intended to resemble large-scale frozen frames, 
        yet real-world recordings inevitably contain slight body movements. The red crops across successive 
        frames (I<sub>i</sub>) highlight these noticeable movements. 
        (Bottom) After our processing, every crop (green boxes) of successive frames remains 
        perfectly static. <strong>Splannequin</strong> analyzes the entire video and resynthesizes a temporally consistent 
        sequence of views at t<sup>*</sup> while preserving overall visual fidelity.
      </p>
    </div>
  </div>
</section>



<section class="hero is-light is-small" >
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel" style="margin: 10pt;">

          <div class="item item-cone">
              <div class="video-compare-container" id="coneDiv" style="width: 100%;">
                  <video class="video" id="cone" loop playsinline autoPlay muted src="./videos/concats/hallway.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                  <canvas height=0 class="videoMerge" id="coneMerge" style="width: 100%;"></canvas>
              </div>
              <div class="video-caption">Hallway Students</div>
          </div>

          <div class="item item-newcone">
              <div class="video-compare-container" id="newconeDiv" style="width: 100%;">
                  <video class="video" id="newcone" loop playsinline autoPlay muted src="./videos/concats/apple.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                  <canvas height=0 class="videoMerge" id="newconeMerge" style="width: 100%;"></canvas>
              </div>
              <div class="video-caption">Hanging Apple</div>
          </div>

          <div class="item">
              <div class="video-compare-container" id="skateboardDiv" style="width: 100%;">
                  <video class="video" id="skateboard" loop playsinline autoPlay muted src="./videos/concats/boy.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                  <canvas height=0 class="videoMerge" id="skateboardMerge" style="width: 100%;"></canvas>
              </div>
              <div class="video-caption">Middle Person</div>
          </div>

          <div class="item item-cookie">
            <div class="video-compare-container" id="cookieDiv" style="width: 100%;">
                <video class="video" id="cookie" loop playsinline autoPlay muted src="./videos/concats/girl_hair.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                <canvas height=0 class="videoMerge" id="cookieMerge" style="width: 100%;"></canvas>
            </div>
            <div class="video-caption">Long-Hair Student</div>
          </div>

          <div class="item">
              <div class="video-compare-container" id="sunflowerDiv" style="width: 100%;">
                  <video class="video" id="sunflower" loop playsinline autoPlay muted src="./videos/concats/light.mp4" onplay="resizeAndPlay(this)" width="100%"></video>
                  <canvas height=0 class="videoMerge" id="sunflowerMerge" style="width: 100%;"></canvas>
              </div>
              <div class="video-caption">Floor Light</div>
          </div>

        </div>
      </div>
    </div>
  </div>
  <h2 class="subtitle is-3 has-text-centered" style="margin-top: -1.2rem;">
    Freezing Results of Our <span class="dnerf">Mannequin-Challenge</span> Dataset
  </h2>
</section>





<section class="section">
  <div class="container is-max-desktop">
      
    <!-- Video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Video</h2>
        <div class="content has-text-justified">
          <p class="has-text-justified">
            Coming soon
          </p>
        </div>
      </div>
    </div>
    <!--/ Video. -->

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p class="has-text-justified">
            Synthesizing high-fidelity frozen 3D scenes from monocular Mannequin-Challenge (MC) videos is a 
            unique problem distinct from standard dynamic scene reconstruction. Instead of focusing on modeling motion, 
            our goal is to create a frozen scene while strategically preserving subtle dynamics to enable user-controlled instant selection. 
            To achieve this, we introduce a novel application of dynamic Gaussian splatting: the scene is modeled dynamically, 
            which retains nearby temporal variation, and a static view is rendered by fixing the model's time parameter. 
            However, under this usage, monocular capture with sparse temporal supervision introduces artifacts 
            like ghosting and blur for Gaussians that become unobserved or occluded at weakly supervised timestamps. 
            We propose Splannequin, an architecture-agnostic regularization that detects two states of Gaussian primitives, 
            hidden and defective, and applies temporal anchoring. Under predominantly forward camera motion, 
            hidden states are anchored to their last well-observed past states, 
            while defective states are anchored to future states with stronger supervision. 
            Our method integrates into existing dynamic Gaussian pipelines via simple loss terms, 
            requires no architectural changes, and adds zero inference overhead. This results in markedly improved visual quality, 
            enabling high-fidelity, user-selectable frozen-time renderings, validated by a 96% user preference.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Pipeline Fig. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Pipeline</h2>
        <div class="pipeline-figure">
          <img src="./static/images/pipeline.png" alt="Pipeline" style="width: 100%; margin-bottom: 30px;"/>
        </div>
        <div class="content has-text-justified">
          <p>
            The pipeline: (1) extracts point clouds from input video, (2) use dynamic Gaussian splatting with dual-detection losses that anchor hidden Gaussians to earlier frames (t'< t) and defective Gaussians to later frames (t < t'), and (3) renders freeze-time videos at any timestamp t*. Temporal distance-based confidence weighting ensures appropriate regularization strength, with closer reference frames providing stronger anchoring than distant ones for robust temporal consistency and artifact elimination.
          </p>
        </div>
      </div>
    </div>
    <!--/ Pipeline Fig. -->

    

    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Time-Camera Conceptualization.</h2>
            <p class="has-text-justified">
              Our approach optimizes problematic Gaussians using pseudo ground truth from the same horizontal coordinates at supervised areas. 
              The bird's-eye view shows a high school hallway with frame samples and image planes.
            </p>
            <div class="agdd-figure">
              <img src="./static/images/time-plane.jpg" alt="Agdd" style="width: 100%; margin: 0 auto 30px auto; display: block;"/>
            </div>
            <p class="has-text-justified">
              Assuming forward camera motion, the diagonal dashed line represents standard dynamic rendering, 
              while the horizontal line shows freeze-time rendering at a fixed timestamp t*. 
              Along this freeze-time line, unsupervised Gaussians are either <strong>hidden</strong> 
              (red points, as the camera has passed them) or <strong>defective</strong> (blue points, not yet well-observed). 
              Our approach regularizes these problematic Gaussians by anchoring them to their supervised counterparts from other timestamps: 
              hidden (red) Gaussians use past states, and defective (blue) Gaussians use future states. 
              The right panel shows a bird's-eye view of a hallway, illustrating how the camera's path creates defective and hidden regions.
            </p>
        </div>
      </div>
    </div>

          <div class="column">
        <div class="content">
          <h2 class="title is-3">User-Selectable Freeze-Time Instants.</h2>
          <div class="unseen-figure">
            <img src="./static/images/user-selection.png" alt="Unseen" style="width: 100%;"/>
          </div>
          <p class="has-text-justified">
            Splannequin empowers users to select the precise moment to freeze, allowing for artistic control over the final scene. 
            Both rows show high-fidelity freeze-time videos generated from the same input sequence but frozen at two different, 
            user-selected timestamps. 
            (Top) At Timestamp 0, the subject in the inset is looking down. 
            (Bottom) At Timestamp 80, captured seconds later, the subject has turned their head. 
            Our method successfully reconstructs both moments with sharp detail and stability, 
            preserving these subtle differences and enabling creative selection based on pose and expression.
          </p>
        </div>
      </div>
  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">
    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Visual Comparison</h2>
        <p class="has-text-justified">
          Baseline dynamic methods are improved by Splannequin to achieve better quality 
          while having the frozen effect without relying on any extra information and diffusion-based hallucination.
          The final results are faithful to content and are free to select any timestamp. 
          Below video comparison shows one improved timestamp.
        </p>
        
        <img src="./static/images/comparison.png" alt="Comparison" style="width: 100%; margin-bottom: 30px;"/>

        <p class="has-text-justified">
          Each column shows freeze-time renderings from all methods at a viewpoint. 
          Rows correspond to direct comparisons of identical viewpoints with baselines: 4DGaussians (top), D-3DGS (middle), 
          and SC-GS (bottom). Adding Splannequin consistently produces sharper, more temporally coherent results, 
          exhibiting reduced ghosting and artifact suppression compared to baseline methods.
        </p>

      </div>
    </div>

    <!--/ Animation. -->
    
    <!-- Visual -->
    <div class="columns is-centered">
      <div class="column is-full-width">
          <div class="text-center ">
              <ul class="nav nav-pills center-pills">
                <li class="method-pill active" data-value="d3dgs"
                    onclick="selectCompVideo(this, activeScenePill)"><a>D-3DGS</a></li>
                <li class="method-pill" data-value="scgs"
                    onclick="selectCompVideo(this, activeScenePill)"><a>SC-GS</a></li>
                <li class="method-pill" data-value="4dgs"
                    onclick="selectCompVideo(this, activeScenePill)"><a>4DGS</a></li>
              </ul>

          </div>

          <script>
            activeMethodPill = document.querySelector('.method-pill.active');
            activeScenePill = document.querySelector('.scene-pill.active');
            activeModePill = document.querySelector('.mode-pill.active');

            updateMethodVisibility('rgb');

            // Auto-load the first video on page load
            if (activeMethodPill && activeScenePill && activeModePill) {
                selectCompVideo(activeMethodPill, activeScenePill, 3, activeModePill);
            }
          </script>

          
          <div class="text-center">
              <div class="video-container">
                  <video class="video" style="height: 280px; max-width: 100%;" m id="compVideo0" loop playsinline autoplay muted>
                      <source src="./videos/comparison/360USID_carton_gscream_vs_ours_rgb.mp4" />
                  </video>
                  <video class="video" style="height: 280px; max-width: 100%;" id="compVideo1" loop playsinline autoplay muted hidden>
                      <source src="./videos/comparison/360USID_carton_gscream_vs_ours_rgb.mp4" />
                  </video>
              </div>


              <div class="text-center" style="color: black; display: none;" id="mode-pills">
                  <div class="btn-group btn-group-sm">
                      <span class="btn btn-primary mode-pill active" data-value="rgb"
                            onclick="updateMethodVisibility('rgb'); selectCompVideo(activeMethodPill, activeScenePill, null, this)">
                          Results
                      </span>
                  </div>
              </div>

              <br>
              <p class="text-justify" style="text-align: center; display: none;">
                Baseline method (left) vs Splannequin (right). Scene trained on <span id="compVideoValue">3</span> views. Try selecting different methods and scenes!
              </p>
              <p class="text-justify" style="text-align: center;">
                <span id="description-text">3</span> Try selecting different methods and scenes!
              </p>
              <script>
                  video0 = document.getElementById("compVideo0");
                  video1 = document.getElementById("compVideo1");
                  video0.addEventListener('loadedmetadata', function() {
                      if (activeVidID == 0 && select){
                          video0.play();
                          // print video size
                          console.log(video0.videoWidth, video0.videoHeight);
                          video0.hidden = false;
                          video1.hidden = true;
                      }
                  });
                  video1.addEventListener('loadedmetadata', function() {
                      if (activeVidID == 1 && select){
                          video1.play();
                          // print video size
                          console.log(video1.videoWidth, video1.videoHeight);
                          video0.hidden = true;
                          video1.hidden = false;
                      }
                  });
              </script>

              <div class="pill-row scene-pills" id="scene-pills">
                  <span class="pill scene-pill active" data-value="1" onclick="selectCompVideo(activeMethodPill, this, 3)">
                      <img class="thumbnail-img" src="thumbnails/1_thumbnail.jpg" alt="1" width="64">
                  </span>
                  <span class="pill scene-pill" data-value="2" onclick="selectCompVideo(activeMethodPill, this, 3)">
                      <img class="thumbnail-img" src="thumbnails/2_thumbnail.jpg" alt="2" width="64">
                  </span>
                  <!-- <span class="pill scene-pill" data-value="3" onclick="selectCompVideo(activeMethodPill, this, 3)">
                      <img class="thumbnail-img" src="thumbnails/3_thumbnail.jpg" alt="3" width="64">
                  </span>
                  <span class="pill scene-pill" data-value="4" onclick="selectCompVideo(activeMethodPill, this, 3)">
                      <img class="thumbnail-img" src="thumbnails/4_thumbnail.jpg" alt="4" width="64">
                  </span> -->
                  <span class="pill scene-pill" data-value="5" onclick="selectCompVideo(activeMethodPill, this, 3)">
                      <img class="thumbnail-img" src="thumbnails/5_thumbnail.jpg" alt="5" width="64">
                  </span>
                  <span class="pill scene-pill" data-value="6" onclick="selectCompVideo(activeMethodPill, this, 3)">
                      <img class="thumbnail-img" src="thumbnails/6_thumbnail.jpg" alt="6" width="64">
                  </span>
                  <span class="pill scene-pill" data-value="7" onclick="selectCompVideo(activeMethodPill, this, 6)">
                      <img class="thumbnail-img" src="thumbnails/7_thumbnail.jpg" alt="7" width="64">
                  </span>
                  <span class="pill scene-pill" data-value="8" onclick="selectCompVideo(activeMethodPill, this, 6)">
                      <img class="thumbnail-img" src="thumbnails/8_thumbnail.jpg" alt="8" width="64">
                  </span>
                  <br>
                  
              </div>

              <script>
                activeMethodPill = document.querySelector('.method-pill.active');
                activeScenePill = document.querySelector('.scene-pill.active');
                activeModePill = document.querySelector('.mode-pill.active');

                updateMethodVisibility('rgb');

                // Auto-load the first video on page load
                if (activeMethodPill && activeScenePill && activeModePill) {
                    selectCompVideo(activeMethodPill, activeScenePill, 3, activeModePill);
                }
              </script>

          </div>
      </div>   
    </div>

    <!-- Quantitative Results. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-2">Quantitative Results</h2>
        <p class="content has-text-justified">
          Quantitative comparison on our real-world dataset. 
          The values represent the percentage improvement Splannequin provides when added to each baseline method (higher is better). 
          Our method consistently enhances all baselines, 
          with the most gains in technical artifact suppression (COVER Technical) and on the lowest-quality frames (IQA Bottom 25%). 
          Methods are abbreviated as: (1) 4DGaussians+, (2) D-3DGS+, and (3) SC-GS+. W.F. is the worst frame.
        </p>
        <img src="./static/images/quantitative.png" alt="Quantitative" style="width: 50%; display: block; margin: 0 auto;"/>
      </div>
    </div>
    <!-- Quantitative Results -->


    <!-- Citation -->
    <div class="columns is-centered">
      <div class="column is-full-width">
          <h2 class="title is-2">Citation</h2>
            <div style="display: inline-block; text-align: left; max-width: 100%; background: #f5f5f5; padding: 10px; border-radius: 5px;">
              <textarea id="bibtex" style="display: none;">
@InProceedings{chien2026splannequin,
  author    = {Hao-Jen Chien, Yi-Chuan Huang, Chung-Ho Wu, Wei-Lun Chao, Yu-Lun Liu},
  title     = {Splannequin: Freezing Monocular Mannequin-Challenge Footage with Dual-Detection Splatting},
  booktitle = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)},
  month     = {March},
  year      = {2026},
}
              </textarea>
            </div>
      </div>
    </div>
    <!-- Citation -->
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template borrowed from <a href="https://nerfies.github.io/">NeRFies</a>, <a href="https://dorverbin.github.io/refnerf">Ref-NeRF</a>, <a href="https://reconfusion.github.io/">ReconFusion</a> and <a href="https://nesf3d.github.io/">NeSF</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
